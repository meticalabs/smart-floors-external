name: Deploy Env Tar to S3

on:
  workflow_dispatch:
    inputs:
      python_version:
        required: false
        type: string
        description: 'Python version'
        default: '3.10'
      aws_region:
        required: false
        type: choice
        description: 'AWS region to deploy'
        default: 'us-east-1'
        options:
          - us-east-1
          - eu-west-1
      bid_floor_model_version:
        required: false
        description: 'Bid Floor Model version to use for installation'
        default: 'latest'
      image_tag_postfix:
        required: false
        description: 'Docker image tag postfix added'
        default: ''
      ecr_repo:
        required: false
        default: 'com.metica.ml.bid-optim-etl-py'
        description: 'ECR Repo to deploy'
      arm:
        required: false
        description: 'ARM based docker image'
        default: 'false'
env:
  us_east_1: dev
  eu_west_1: prod-eu
  us_east_1_role: ${{ secrets.DEV_AWS_DEPLOY_ROLE }}
  eu_west_1_role: ${{ secrets.PROD_EU_AWS_DEPLOY_ROLE }}
  BRANCH_NAME: ${{ github.head_ref || github.ref_name }}

permissions:
  id-token: write
  contents: read
  actions: read

jobs:
  variables:
    outputs:
      ENVIRONMENT: ${{ steps.var.outputs.ENVIRONMENT }}
    runs-on: "ubuntu-latest"
    steps:
      - name: Setting global variables
        uses: actions/github-script@v6
        id: var
        with:
          script: |
            core.setOutput('ENVIRONMENT', '${{ inputs.aws_region }}'.toLowerCase().replaceAll(/[/-]/g, '_').trim('_'));
  build:
    needs: [ variables ]
    runs-on: ubuntu-latest-m
    env:
      CI_GITHUB_TOKEN: ${{ secrets.CI_GITHUB_TOKEN }}
      ENVIRONMENT: $${{ needs.variables.outputs.ENVIRONMENT }}
      ROLE: $${{ format('{0}_role', needs.variables.outputs.ENVIRONMENT) }}
    steps:
      - uses: actions/checkout@v3

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          # Install a specific version of uv.
          version: "0.6.14"

      - name: Make All
        uses: meticalabs/gh_workflows/.github/actions/poetry-conda-install@main
        with:
          github_token: ${{ secrets.CI_GITHUB_TOKEN }}
          python_version: ${{ inputs.python_version }}
          branch: ${{ env.BRANCH_NAME }}
          run_make_all: true

      - name: Get project name and version
        shell: bash -el {0}
        run: |
          pip install tomli
          NAME=$(python -c "import tomli; print(tomli.load(open('pyproject.toml', 'rb'))['project']['name'].replace('-', '_'))")
          VERSION=$(python -c "import tomli; print(tomli.load(open('pyproject.toml', 'rb'))['project']['version'])")
          echo "project_version=$VERSION" >> $GITHUB_OUTPUT
          echo "project_name=$NAME" >> $GITHUB_OUTPUT
        id: project

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.GH_OPENID_ROLE_ARN }}
          aws-region: ${{ inputs.aws_region }}

      - name: Building tar from venv and publishing to s3
        shell: bash -el {0}
        run: |
          export $(printf "AWS_ACCESS_KEY_ID=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s" \
          $(aws sts assume-role \
          --role-arn ${{env.ROLE}} \
          --role-session-name MySessionName \
          --query "Credentials.[AccessKeyId,SecretAccessKey,SessionToken]" \
          --output text))
          conda info
          conda activate test
          conda info
          python --version
          proj_wheel_file=$(echo "${{steps.project.outputs.project_name}}-${{steps.project.outputs.project_version}}-py3-none-any.whl")
          s3_env_target=$(echo "s3://com.metica.${{env.ENVIRONMENT}}.dplat.artifacts/pyspark/envs/")
          env_tar=$(echo "${{steps.project.outputs.project_name}}-${{steps.project.outputs.project_version}}.tar.gz")
          echo "Building $env_tar file from venv"
          which python
          python -m pip install ./dist/$proj_wheel_file
          python -m pip install conda-pack
          conda list
          conda pack -f -o $env_tar
          aws_sts=$(aws sts get-caller-identity)
          echo $aws_sts
          echo "Publishing JAR $env_tar to $s3_env_target"
          aws s3 cp $env_tar $s3_env_target
          echo "Publishing the .tar.gz from dist for ray cluster bootstrap"
          aws s3 cp ./dist/$env_tar s3://com.metica.${{env.ENVIRONMENT}}.dplat.artifacts/pyspark/bootstrap/

      - name: Docker deploy
        uses: meticalabs/bid-optim-etl-py/.github/actions/publish-py-img-docker@main
        with:
          github_token: ${{ secrets.CI_GITHUB_TOKEN }}
          bid_floor_model_version: ${{ inputs.bid_floor_model_version }}
          image_tag_postfix: ${{ inputs.image_tag_postfix }}
          aws_region: ${{ inputs.aws_region }}
          ecr_repo: ${{ inputs.ecr_repo }}
          arm: ${{ inputs.arm }}
          gh_openid_role_arn: ${{ secrets.GH_OPENID_ROLE_ARN }}